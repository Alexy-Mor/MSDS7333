{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKv-SbdrXjFF"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers \n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a2IubDSiZpoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "i8imqg_-YYv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip file and store in csv\n",
        "import gzip\n",
        "\n",
        "\n",
        "with gzip.open('/content/drive/MyDrive/Colab Notebooks/CS6/all_train.csv.gz', 'rt', newline='') as csv_file:\n",
        "    csv_data = csv_file.read()\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/CS6/all_train.csv', 'wt') as out_file:\n",
        "         out_file.write(csv_data)"
      ],
      "metadata": {
        "id": "lM-DAk8GrtLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Load up data and show.\n",
        " df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS6/all_train.csv')\n",
        " df.head()"
      ],
      "metadata": {
        "id": "GjFeHB9KbG2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename labels column \n",
        "df2=df\n",
        "df2.rename(columns = {'# label':'detection'}, inplace = True)\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "ut6NoK_d1UdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display a summary of variables\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "NZD-xw6p6UKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary of Attributes in the dataframe\n",
        "df2.describe()"
      ],
      "metadata": {
        "id": "ZFH-3SRU7DQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace all '0.0' with '0' and '1.0' with '1' in the \"# labels\" column.\n",
        "df2['detection'] = df2['detection'].map({0.0: 0, 1.0: 1})\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "vouhjMPx6mGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "sKIGXVZ0rCfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see if there are nulls\n",
        "df2.isnull().sum()"
      ],
      "metadata": {
        "id": "7Sy8nLHizwJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count values in label\n",
        "df2['detection'].value_counts()"
      ],
      "metadata": {
        "id": "V75Vk-HKpJm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XTidamYGt5Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "labels = [\"0 = No Detection\", \"1 = Detection\"]\n",
        "ax.bar(labels,df2[\"detection\"].value_counts())\n",
        "plt.ylabel(\"counts\")\n",
        "plt.title('Counts of Particle Detection')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vNxigaR7z_Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Examine the mean of the Numerical Values by detection\n",
        "df2.groupby(['detection']).mean()"
      ],
      "metadata": {
        "id": "kvGFJ_FE7hD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Examine the mean of the numerical values by mass\n",
        "df2.groupby('mass')['detection'].value_counts()"
      ],
      "metadata": {
        "id": "DmG4VojI-8VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "X0dxYBur5q_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Violinplot of Detection and Mass\n",
        "import seaborn as sns\n",
        "sns.set_palette(\"pastel\")\n",
        "sns.violinplot(x='detection',y='mass', data = df2)\n",
        "plt.title('Detection by Mass')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "11qcxQOP_NHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Potential attribute with all factors \n",
        "sns.pairplot(df2, kind=\"scatter\", hue = \"detection\", markers = [\"o\", \"s\"], palette = \"Set2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DbExUiE9_-pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size\n",
        "kernel_size = 3"
      ],
      "metadata": {
        "id": "Zb2FkU1HCdAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6e8af99"
      },
      "outputs": [],
      "source": [
        "x = df2.loc[:,df2.columns !='detection']\n",
        "y = df2['detection']  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcYScek_sPF-"
      },
      "outputs": [],
      "source": [
        "# Range of 0,1 is important for well trained neural networks\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_train = scaler.fit_transform(x)\n",
        "\n",
        "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
        "print(\"Note: median values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[27], scaler.min_[27]))\n",
        "multiplied_by = scaler.scale_[27]\n",
        "added = scaler.min_[27]\n",
        "\n",
        "scaled_train_df = pd.DataFrame(scaled_train, columns=x.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "fnqGAM4usPF_"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "for i in scaled_train_df:\n",
        "    scaled_train_df[i].hist()\n",
        "    plt.title(i)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09d783fc"
      },
      "outputs": [],
      "source": [
        "# Split into test/train \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_train_df, y, test_size=0.3,random_state=444)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and build layers\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(28,)))\n",
        "model.add(layers.Dense(50,activation='relu'))  "
      ],
      "metadata": {
        "id": "RdQNaPqwYjp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['mean_squared_error','accuracy'])"
      ],
      "metadata": {
        "id": "fN9nCua0YqfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test), batch_size=128)"
      ],
      "metadata": {
        "id": "xUCchDhuYwdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot loss\n",
        "train_loss = model.history.history['loss']\n",
        "val_loss = model.history.history['val_loss']\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lVcaoIj-Y0Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Accuacy\n",
        "train_acc = model.history.history['accuracy']\n",
        "val_acc = model.history.history['val_accuracy'] \n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8oJ4Wvv0Y0Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DofLOrrYFrML"
      },
      "outputs": [],
      "source": [
        "# Create the model and build layers\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(28,)))\n",
        "model.add(layers.Dense(50,activation='relu'))  \n",
        "model.add(layers.Dense(25, activation='sigmoid'))   \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['mean_squared_error','accuracy'])"
      ],
      "metadata": {
        "id": "XwdeDQPQHEkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test), batch_size=128)"
      ],
      "metadata": {
        "id": "ZVMO43YsHLyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot loss\n",
        "train_loss = model.history.history['loss']\n",
        "val_loss = model.history.history['val_loss']\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZwFJCEw6HLo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Accuacy\n",
        "train_acc = model.history.history['accuracy']\n",
        "val_acc = model.history.history['val_accuracy'] \n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VHLu_lXzHLcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtDiFu0tsPGC"
      },
      "outputs": [],
      "source": [
        "# Create the model and build layers\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(28,)))\n",
        "model.add(layers.Dense(64,activation='tanh'))  \n",
        "model.add(layers.Dense(32, activation='relu'))   \n",
        "model.add(layers.Dense(16, activation='linear'))  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yuOyZUusPGC"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['mean_squared_error','accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcfMS7eBsPGD"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test), batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot loss\n",
        "train_loss = model.history.history['loss']\n",
        "val_loss = model.history.history['val_loss']\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c9zt9Yt6ZLqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Accuacy\n",
        "train_acc = model.history.history['accuracy']\n",
        "val_acc = model.history.history['val_accuracy'] \n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZIF5dOkBIAfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}